{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text_Classification_LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "DptK-GYLokpW"
      },
      "source": [
        "import os \n",
        "os.chdir(\"/\")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEvwnx76LNDn",
        "outputId": "64e72141-013e-4479-d5e2-a0213c483e1e"
      },
      "source": [
        "!wget -O sample.csv https://gist.githubusercontent.com/hskalin/ed2d2af6d9a14fe4487fdfdadbf84ea1/raw/405ae905047b686a1aa24ce78c363d4ad6bbc61e/sample.csv"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-09 13:04:31--  https://gist.githubusercontent.com/hskalin/ed2d2af6d9a14fe4487fdfdadbf84ea1/raw/405ae905047b686a1aa24ce78c363d4ad6bbc61e/sample.csv\n",
            "Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 37393 (37K) [text/plain]\n",
            "Saving to: ‘sample.csv’\n",
            "\n",
            "sample.csv          100%[===================>]  36.52K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2021-11-09 13:04:32 (8.48 MB/s) - ‘sample.csv’ saved [37393/37393]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6OtROfjJnn7",
        "outputId": "7afefd81-3deb-4f06-ffa7-05dc3d7e7f1c"
      },
      "source": [
        "!pip install deepspeed"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deepspeed\n",
            "  Downloading deepspeed-0.5.5.tar.gz (488 kB)\n",
            "\u001b[K     |████████████████████████████████| 488 kB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from deepspeed) (1.9.0+cu111)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from deepspeed) (4.62.3)\n",
            "Collecting tensorboardX==1.8\n",
            "  Downloading tensorboardX-1.8-py2.py3-none-any.whl (216 kB)\n",
            "\u001b[K     |████████████████████████████████| 216 kB 47.4 MB/s \n",
            "\u001b[?25hCollecting ninja\n",
            "  Downloading ninja-1.10.2.2-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (108 kB)\n",
            "\u001b[K     |████████████████████████████████| 108 kB 48.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from deepspeed) (1.19.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from deepspeed) (5.4.8)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from deepspeed) (21.0)\n",
            "Collecting triton\n",
            "  Downloading triton-1.1.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 18.2 MB 44 kB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX==1.8->deepspeed) (3.17.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tensorboardX==1.8->deepspeed) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->deepspeed) (2.4.7)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->deepspeed) (3.7.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from triton->deepspeed) (3.3.0)\n",
            "Building wheels for collected packages: deepspeed\n",
            "  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deepspeed: filename=deepspeed-0.5.5-py3-none-any.whl size=496219 sha256=37439f76e858c5c162eede00d87613b51d15c5612364e4b1461398c1cea457f4\n",
            "  Stored in directory: /root/.cache/pip/wheels/65/9a/da/f8470dc64c7deabe748f02291ed708b09887740f002fd770e3\n",
            "Successfully built deepspeed\n",
            "Installing collected packages: triton, tensorboardX, ninja, deepspeed\n",
            "Successfully installed deepspeed-0.5.5 ninja-1.10.2.2 tensorboardX-1.8 triton-1.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxEb1acoJj1Z",
        "outputId": "dbfa1e2d-1cf9-4711-8c61-03d61105bca5"
      },
      "source": [
        "!deepspeed textclassification_lstm.py --deepspeed_config ds_config.json "
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2021-11-09 14:01:21,818] [WARNING] [runner.py:121:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.\n",
            "[2021-11-09 14:01:21,841] [INFO] [runner.py:355:main] cmd = /usr/bin/python3 -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMF19 --master_addr=127.0.0.1 --master_port=29500 textclassification_lstm.py --deepspeed_config ds_config.json\n",
            "[2021-11-09 14:01:22,842] [INFO] [launch.py:73:main] 0 NCCL_VERSION 2.7.8\n",
            "[2021-11-09 14:01:22,843] [INFO] [launch.py:80:main] WORLD INFO DICT: {'localhost': [0]}\n",
            "[2021-11-09 14:01:22,843] [INFO] [launch.py:89:main] nnodes=1, num_local_procs=1, node_rank=0\n",
            "[2021-11-09 14:01:22,843] [INFO] [launch.py:101:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})\n",
            "[2021-11-09 14:01:22,843] [INFO] [launch.py:102:main] dist_world_size=1\n",
            "[2021-11-09 14:01:22,843] [INFO] [launch.py:105:main] Setting CUDA_VISIBLE_DEVICES=0\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[2021-11-09 14:01:27,527] [INFO] [logging.py:68:log_dist] [Rank -1] DeepSpeed info: version=0.5.5, git-hash=unknown, git-branch=unknown\n",
            "[2021-11-09 14:01:27,528] [INFO] [distributed.py:47:init_distributed] Initializing torch distributed with backend: nccl\n",
            "[2021-11-09 14:01:29,833] [INFO] [logging.py:68:log_dist] [Rank 0] initializing deepspeed groups\n",
            "[2021-11-09 14:01:29,833] [INFO] [logging.py:68:log_dist] [Rank 0] initializing deepspeed model parallel group with size 1\n",
            "[2021-11-09 14:01:29,834] [INFO] [logging.py:68:log_dist] [Rank 0] initializing deepspeed expert parallel group with size 1\n",
            "[2021-11-09 14:01:29,834] [INFO] [logging.py:68:log_dist] [Rank 0] creating expert data parallel process group with ranks: [0]\n",
            "[2021-11-09 14:01:29,835] [INFO] [logging.py:68:log_dist] [Rank 0] creating expert parallel process group with ranks: [0]\n",
            "[2021-11-09 14:01:29,920] [INFO] [engine.py:208:__init__] DeepSpeed Flops Profiler Enabled: False\n",
            "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
            "Detected CUDA files, patching ldflags\n",
            "Emitting ninja build file /root/.cache/torch_extensions/fused_adam/build.ninja...\n",
            "Building extension module fused_adam...\n",
            "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "ninja: no work to do.\n",
            "Loading extension module fused_adam...\n",
            "Time to load fused_adam op: 0.2791612148284912 seconds\n",
            "[2021-11-09 14:01:31,150] [INFO] [engine.py:886:_configure_optimizer] Using DeepSpeed Optimizer param name adam as basic optimizer\n",
            "[2021-11-09 14:01:31,151] [INFO] [engine.py:893:_configure_optimizer] DeepSpeed Basic Optimizer = FusedAdam\n",
            "[2021-11-09 14:01:31,151] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Final Optimizer = adam\n",
            "[2021-11-09 14:01:31,151] [INFO] [engine.py:596:_configure_lr_scheduler] DeepSpeed using configured LR scheduler = WarmupLR\n",
            "[2021-11-09 14:01:31,151] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed LR Scheduler = <deepspeed.runtime.lr_schedules.WarmupLR object at 0x7fd003dcafd0>\n",
            "[2021-11-09 14:01:31,151] [INFO] [logging.py:68:log_dist] [Rank 0] step=0, skipped=0, lr=[0.001], mom=[[0.8, 0.999]]\n",
            "[2021-11-09 14:01:31,152] [INFO] [config.py:958:print] DeepSpeedEngine configuration:\n",
            "[2021-11-09 14:01:31,152] [INFO] [config.py:962:print]   activation_checkpointing_config  {\n",
            "    \"partition_activations\": false, \n",
            "    \"contiguous_memory_optimization\": false, \n",
            "    \"cpu_checkpointing\": false, \n",
            "    \"number_checkpoints\": null, \n",
            "    \"synchronize_checkpoint_boundary\": false, \n",
            "    \"profile\": false\n",
            "}\n",
            "[2021-11-09 14:01:31,152] [INFO] [config.py:962:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
            "[2021-11-09 14:01:31,152] [INFO] [config.py:962:print]   allreduce_always_fp32 ........ False\n",
            "[2021-11-09 14:01:31,152] [INFO] [config.py:962:print]   amp_enabled .................. False\n",
            "[2021-11-09 14:01:31,152] [INFO] [config.py:962:print]   amp_params ................... False\n",
            "[2021-11-09 14:01:31,152] [INFO] [config.py:962:print]   bfloat16_enabled ............. False\n",
            "[2021-11-09 14:01:31,153] [INFO] [config.py:962:print]   checkpoint_tag_validation_enabled  True\n",
            "[2021-11-09 14:01:31,153] [INFO] [config.py:962:print]   checkpoint_tag_validation_fail  False\n",
            "[2021-11-09 14:01:31,153] [INFO] [config.py:962:print]   curriculum_enabled ........... False\n",
            "[2021-11-09 14:01:31,153] [INFO] [config.py:962:print]   curriculum_params ............ False\n",
            "[2021-11-09 14:01:31,153] [INFO] [config.py:962:print]   dataloader_drop_last ......... False\n",
            "[2021-11-09 14:01:31,153] [INFO] [config.py:962:print]   disable_allgather ............ False\n",
            "[2021-11-09 14:01:31,153] [INFO] [config.py:962:print]   dump_state ................... False\n",
            "[2021-11-09 14:01:31,153] [INFO] [config.py:962:print]   dynamic_loss_scale_args ...... None\n",
            "[2021-11-09 14:01:31,153] [INFO] [config.py:962:print]   eigenvalue_enabled ........... False\n",
            "[2021-11-09 14:01:31,153] [INFO] [config.py:962:print]   eigenvalue_gas_boundary_resolution  1\n",
            "[2021-11-09 14:01:31,153] [INFO] [config.py:962:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
            "[2021-11-09 14:01:31,153] [INFO] [config.py:962:print]   eigenvalue_layer_num ......... 0\n",
            "[2021-11-09 14:01:31,153] [INFO] [config.py:962:print]   eigenvalue_max_iter .......... 100\n",
            "[2021-11-09 14:01:31,154] [INFO] [config.py:962:print]   eigenvalue_stability ......... 1e-06\n",
            "[2021-11-09 14:01:31,154] [INFO] [config.py:962:print]   eigenvalue_tol ............... 0.01\n",
            "[2021-11-09 14:01:31,154] [INFO] [config.py:962:print]   eigenvalue_verbose ........... False\n",
            "[2021-11-09 14:01:31,154] [INFO] [config.py:962:print]   elasticity_enabled ........... False\n",
            "[2021-11-09 14:01:31,154] [INFO] [config.py:962:print]   flops_profiler_config ........ {\n",
            "    \"enabled\": false, \n",
            "    \"profile_step\": 1, \n",
            "    \"module_depth\": -1, \n",
            "    \"top_modules\": 1, \n",
            "    \"detailed\": true, \n",
            "    \"output_file\": null\n",
            "}\n",
            "[2021-11-09 14:01:31,154] [INFO] [config.py:962:print]   fp16_enabled ................. False\n",
            "[2021-11-09 14:01:31,154] [INFO] [config.py:962:print]   fp16_master_weights_and_gradients  False\n",
            "[2021-11-09 14:01:31,154] [INFO] [config.py:962:print]   fp16_mixed_quantize .......... False\n",
            "[2021-11-09 14:01:31,154] [INFO] [config.py:962:print]   global_rank .................. 0\n",
            "[2021-11-09 14:01:31,154] [INFO] [config.py:962:print]   gradient_accumulation_steps .. 1\n",
            "[2021-11-09 14:01:31,154] [INFO] [config.py:962:print]   gradient_clipping ............ 0.0\n",
            "[2021-11-09 14:01:31,155] [INFO] [config.py:962:print]   gradient_predivide_factor .... 1.0\n",
            "[2021-11-09 14:01:31,155] [INFO] [config.py:962:print]   initial_dynamic_scale ........ 4294967296\n",
            "[2021-11-09 14:01:31,155] [INFO] [config.py:962:print]   loss_scale ................... 0\n",
            "[2021-11-09 14:01:31,155] [INFO] [config.py:962:print]   memory_breakdown ............. False\n",
            "[2021-11-09 14:01:31,155] [INFO] [config.py:962:print]   optimizer_legacy_fusion ...... False\n",
            "[2021-11-09 14:01:31,155] [INFO] [config.py:962:print]   optimizer_name ............... adam\n",
            "[2021-11-09 14:01:31,155] [INFO] [config.py:962:print]   optimizer_params ............. {'lr': 0.001, 'betas': [0.8, 0.999], 'eps': 1e-08, 'weight_decay': 3e-07}\n",
            "[2021-11-09 14:01:31,155] [INFO] [config.py:962:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}\n",
            "[2021-11-09 14:01:31,155] [INFO] [config.py:962:print]   pld_enabled .................. False\n",
            "[2021-11-09 14:01:31,155] [INFO] [config.py:962:print]   pld_params ................... False\n",
            "[2021-11-09 14:01:31,155] [INFO] [config.py:962:print]   prescale_gradients ........... False\n",
            "[2021-11-09 14:01:31,155] [INFO] [config.py:962:print]   quantize_change_rate ......... 0.001\n",
            "[2021-11-09 14:01:31,155] [INFO] [config.py:962:print]   quantize_groups .............. 1\n",
            "[2021-11-09 14:01:31,155] [INFO] [config.py:962:print]   quantize_offset .............. 1000\n",
            "[2021-11-09 14:01:31,156] [INFO] [config.py:962:print]   quantize_period .............. 1000\n",
            "[2021-11-09 14:01:31,156] [INFO] [config.py:962:print]   quantize_rounding ............ 0\n",
            "[2021-11-09 14:01:31,156] [INFO] [config.py:962:print]   quantize_start_bits .......... 16\n",
            "[2021-11-09 14:01:31,156] [INFO] [config.py:962:print]   quantize_target_bits ......... 8\n",
            "[2021-11-09 14:01:31,156] [INFO] [config.py:962:print]   quantize_training_enabled .... False\n",
            "[2021-11-09 14:01:31,156] [INFO] [config.py:962:print]   quantize_type ................ 0\n",
            "[2021-11-09 14:01:31,156] [INFO] [config.py:962:print]   quantize_verbose ............. False\n",
            "[2021-11-09 14:01:31,156] [INFO] [config.py:962:print]   scheduler_name ............... WarmupLR\n",
            "[2021-11-09 14:01:31,156] [INFO] [config.py:962:print]   scheduler_params ............. {'warmup_min_lr': 0, 'warmup_max_lr': 0.001, 'warmup_num_steps': 1000}\n",
            "[2021-11-09 14:01:31,156] [INFO] [config.py:962:print]   sparse_attention ............. None\n",
            "[2021-11-09 14:01:31,156] [INFO] [config.py:962:print]   sparse_gradients_enabled ..... False\n",
            "[2021-11-09 14:01:31,156] [INFO] [config.py:962:print]   steps_per_print .............. 2000\n",
            "[2021-11-09 14:01:31,156] [INFO] [config.py:962:print]   tensorboard_enabled .......... False\n",
            "[2021-11-09 14:01:31,157] [INFO] [config.py:962:print]   tensorboard_job_name ......... DeepSpeedJobName\n",
            "[2021-11-09 14:01:31,157] [INFO] [config.py:962:print]   tensorboard_output_path ...... \n",
            "[2021-11-09 14:01:31,157] [INFO] [config.py:962:print]   train_batch_size ............. 1\n",
            "[2021-11-09 14:01:31,157] [INFO] [config.py:962:print]   train_micro_batch_size_per_gpu  1\n",
            "[2021-11-09 14:01:31,157] [INFO] [config.py:962:print]   use_quantizer_kernel ......... False\n",
            "[2021-11-09 14:01:31,157] [INFO] [config.py:962:print]   wall_clock_breakdown ......... False\n",
            "[2021-11-09 14:01:31,157] [INFO] [config.py:962:print]   world_size ................... 1\n",
            "[2021-11-09 14:01:31,157] [INFO] [config.py:962:print]   zero_allow_untested_optimizer  False\n",
            "[2021-11-09 14:01:31,157] [INFO] [config.py:962:print]   zero_config .................. {\n",
            "    \"stage\": 0, \n",
            "    \"contiguous_gradients\": true, \n",
            "    \"reduce_scatter\": true, \n",
            "    \"reduce_bucket_size\": 5.000000e+08, \n",
            "    \"allgather_partitions\": true, \n",
            "    \"allgather_bucket_size\": 5.000000e+08, \n",
            "    \"overlap_comm\": false, \n",
            "    \"load_from_fp32_weights\": true, \n",
            "    \"elastic_checkpoint\": true, \n",
            "    \"offload_param\": null, \n",
            "    \"offload_optimizer\": null, \n",
            "    \"sub_group_size\": 1.000000e+09, \n",
            "    \"prefetch_bucket_size\": 5.000000e+07, \n",
            "    \"param_persistence_threshold\": 1.000000e+05, \n",
            "    \"max_live_parameters\": 1.000000e+09, \n",
            "    \"max_reuse_distance\": 1.000000e+09, \n",
            "    \"gather_fp16_weights_on_model_save\": false, \n",
            "    \"ignore_unused_parameters\": true, \n",
            "    \"round_robin_gradients\": false, \n",
            "    \"legacy_stage1\": false\n",
            "}\n",
            "[2021-11-09 14:01:31,157] [INFO] [config.py:962:print]   zero_enabled ................. False\n",
            "[2021-11-09 14:01:31,158] [INFO] [config.py:962:print]   zero_optimization_stage ...... 0\n",
            "[2021-11-09 14:01:31,158] [INFO] [config.py:969:print]   json = {\n",
            "    \"train_batch_size\": 1, \n",
            "    \"steps_per_print\": 2.000000e+03, \n",
            "    \"optimizer\": {\n",
            "        \"type\": \"Adam\", \n",
            "        \"params\": {\n",
            "            \"lr\": 0.001, \n",
            "            \"betas\": [0.8, 0.999], \n",
            "            \"eps\": 1e-08, \n",
            "            \"weight_decay\": 3e-07\n",
            "        }\n",
            "    }, \n",
            "    \"scheduler\": {\n",
            "        \"type\": \"WarmupLR\", \n",
            "        \"params\": {\n",
            "            \"warmup_min_lr\": 0, \n",
            "            \"warmup_max_lr\": 0.001, \n",
            "            \"warmup_num_steps\": 1000\n",
            "        }\n",
            "    }, \n",
            "    \"wall_clock_breakdown\": false\n",
            "}\n",
            "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
            "Emitting ninja build file /root/.cache/torch_extensions/utils/build.ninja...\n",
            "Building extension module utils...\n",
            "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "ninja: no work to do.\n",
            "Loading extension module utils...\n",
            "Time to load utils op: 0.29121828079223633 seconds\n",
            "Epoch1\n",
            "Epoch ran :2\n",
            "Input vector\n",
            "[[ 7 17 10 ... 27 27 27]]\n",
            "Probs\n",
            "tensor([[0.0716, 0.1911, 0.1855, 0.1911, 0.1696, 0.1911]], device='cuda:0',\n",
            "       grad_fn=<SoftmaxBackward>)\n",
            "1\n",
            "Epoch2\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "Epoch ran :3\n",
            "Input vector\n",
            "[[ 7 17 10 ... 27 27 27]]\n",
            "Probs\n",
            "tensor([[0.2147, 0.2928, 0.1400, 0.0623, 0.1451, 0.1451]], device='cuda:0',\n",
            "       grad_fn=<SoftmaxBackward>)\n",
            "1\n",
            "Epoch3\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "Epoch ran :4\n",
            "Input vector\n",
            "[[ 7 17 10 ... 27 27 27]]\n",
            "Probs\n",
            "tensor([[0.2421, 0.1905, 0.1680, 0.1680, 0.0633, 0.1680]], device='cuda:0',\n",
            "       grad_fn=<SoftmaxBackward>)\n",
            "0\n",
            "Epoch4\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "Epoch ran :5\n",
            "Input vector\n",
            "[[ 7 17 10 ... 27 27 27]]\n",
            "Probs\n",
            "tensor([[0.1901, 0.1743, 0.1743, 0.1743, 0.1743, 0.1126]], device='cuda:0',\n",
            "       grad_fn=<SoftmaxBackward>)\n",
            "0\n",
            "Epoch5\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "Epoch ran :6\n",
            "YO\n",
            "[W ProcessGroupNCCL.cpp:1569] Rank 0 using best-guess GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device.\n",
            "[2021-11-09 14:02:00,108] [INFO] [logging.py:68:log_dist] [Rank 0] Saving model checkpoint: ./lstm_big_model_3_with_padding_epoch_5.pth/global_step275/mp_rank_00_model_states.pt\n",
            "Input vector\n",
            "[[ 7 17 10 ... 27 27 27]]\n",
            "Probs\n",
            "tensor([[0.2343, 0.2343, 0.1939, 0.2343, 0.0389, 0.0643]], device='cuda:0',\n",
            "       grad_fn=<SoftmaxBackward>)\n",
            "0\n",
            "Epoch6\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "Epoch ran :7\n",
            "Input vector\n",
            "[[ 7 17 10 ... 27 27 27]]\n",
            "Probs\n",
            "tensor([[0.1364, 0.5547, 0.1364, 0.1364, 0.0211, 0.0151]], device='cuda:0',\n",
            "       grad_fn=<SoftmaxBackward>)\n",
            "1\n",
            "Epoch7\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "Epoch ran :8\n",
            "Input vector\n",
            "[[ 7 17 10 ... 27 27 27]]\n",
            "Probs\n",
            "tensor([[0.4365, 0.1658, 0.1658, 0.1658, 0.0214, 0.0447]], device='cuda:0',\n",
            "       grad_fn=<SoftmaxBackward>)\n",
            "0\n",
            "Epoch8\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "Epoch ran :9\n",
            "Input vector\n",
            "[[ 7 17 10 ... 27 27 27]]\n",
            "Probs\n",
            "tensor([[0.1460, 0.6843, 0.1460, 0.0097, 0.0039, 0.0102]], device='cuda:0',\n",
            "       grad_fn=<SoftmaxBackward>)\n",
            "1\n",
            "Epoch9\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "Epoch ran :10\n",
            "Input vector\n",
            "[[ 7 17 10 ... 27 27 27]]\n",
            "Probs\n",
            "tensor([[0.6416, 0.1722, 0.1722, 0.0076, 0.0033, 0.0033]], device='cuda:0',\n",
            "       grad_fn=<SoftmaxBackward>)\n",
            "0\n",
            "Epoch10\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "Epoch ran :11\n",
            "YO\n",
            "[2021-11-09 14:02:28,702] [INFO] [logging.py:68:log_dist] [Rank 0] Saving model checkpoint: ./lstm_big_model_3_with_padding_epoch_10.pth/global_step550/mp_rank_00_model_states.pt\n",
            "Input vector\n",
            "[[ 7 17 10 ... 27 27 27]]\n",
            "Probs\n",
            "tensor([[0.6726, 0.1220, 0.0631, 0.0172, 0.0032, 0.1220]], device='cuda:0',\n",
            "       grad_fn=<SoftmaxBackward>)\n",
            "0\n",
            "Epoch11\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "Epoch ran :12\n",
            "Input vector\n",
            "[[ 7 17 10 ... 27 27 27]]\n",
            "Probs\n",
            "tensor([[0.3372, 0.5045, 0.0193, 0.0682, 0.0682, 0.0026]], device='cuda:0',\n",
            "       grad_fn=<SoftmaxBackward>)\n",
            "1\n",
            "Epoch12\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "Epoch ran :13\n",
            "Input vector\n",
            "[[ 7 17 10 ... 27 27 27]]\n",
            "Probs\n",
            "tensor([[0.2227, 0.6044, 0.0693, 0.0109, 0.0049, 0.0878]], device='cuda:0',\n",
            "       grad_fn=<SoftmaxBackward>)\n",
            "1\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.00      0.00      0.00       0.0\n",
            "           2       0.00      0.00      0.00       1.0\n",
            "           3       0.00      0.00      0.00       4.0\n",
            "           4       0.00      0.00      0.00       5.0\n",
            "           5       0.00      0.00      0.00       4.0\n",
            "\n",
            "    accuracy                           0.00      14.0\n",
            "   macro avg       0.00      0.00      0.00      14.0\n",
            "weighted avg       0.00      0.00      0.00      14.0\n",
            "\n",
            "Index(['iter', ' loss'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-dPrYqEunfW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}